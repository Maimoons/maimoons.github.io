---
---
@inproceedings{10.1145/3395035.3425190,
author = {Erekat, Diyala and Hammal, Zakia and Siddiqui, Maimoon and Dibeklio\u{g}lu, Hamdi},
title = {Enforcing Multilabel Consistency for Automatic Spatio-Temporal Assessment of Shoulder Pain Intensity},
year = {2020},
isbn = {9781450380027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3395035.3425190},
abstract = {The standard clinical assessment of pain is limited primarily to self-reported pain or clinician impression. While the self-reported measurement of pain is useful, in some circumstances it cannot be obtained. Automatic facial expression analysis has emerged asa potential solution for an objective, reliable, and valid measurement of pain. In this study, we propose a video based approach for the automatic measurement of self-reported pain and the observer pain intensity, respectively. To this end, we explore the added value of three self-reported pain scales, i.e., the Visual Analog Scale(VAS), the Sensory Scale (SEN), and the Affective Motivational Scale(AFF), as well as the Observer Pain Intensity (OPI) rating for a reliable assessment of pain intensity from facial expression. Using a spatio-temporal Convolutional Neural Network - Recurrent Neural Network (CNN-RNN) architecture, we propose to jointly minimize the mean absolute error of pain scores estimation for each of thesescales while maximizing the consistency between them. The reliability of the proposed method is evaluated on the benchmark database for pain measurement from videos, namely, the UNBC-McMaster Pain Archive. Our results show that enforcing the consistency be-tween different self-reported pain intensity scores collected using different pain scales enhances the quality of predictions and improve the state of the art in automatic self-reported pain estimation.The obtained results suggest that automatic assessment of self-reported pain intensity from videos is feasible, and could be used as a complementary instrument to unburden caregivers, specially for vulnerable populations that need constant monitoring.},
booktitle = {Companion Publication of the 2020 International Conference on Multimodal Interaction},
pages = {156â€“164},
numpages = {9},
keywords = {pain, convolutional neural network, visual analogue scale, dynamics, observer pain intensity, facial expression, recurrent neural network},
location = {Virtual Event, Netherlands},
series = {ICMI '20 Companion}
}


